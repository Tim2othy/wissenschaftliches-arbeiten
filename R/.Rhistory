summary_lm <- summary(lm_model)
# Summary
summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
x = train_data[,fix]
View(x)
# BART model
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
# BART model
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
bart_model <- wbart(x.train = x_train, y.train = y_train, x.test = x_valid, nskip = 1000, ndpost = 1000, printevery = 500)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Create TREE
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Create REGR
lm_model <- lm(G3 ~ ., data = train_data)
summary(lm_model)
install.packages("lintr")
lint("<looking_at_data>.R>")
lint("<looking_at_data>.R>")
library(data.tree)
library(lintr)
lint("<looking_at_data>.R>")
setwd()
setwd(timtj)
setwd(Users)
setwd(C:\Users\timtj\GitHub\wissenschaftliches-arbeiten\R)
setwd("C:\Users\timtj\GitHub\wissenschaftliches-arbeiten\R")
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("<looking_at_data>.R>")
lint("<looking_at_data>.R")
getwd()
lint("<looking_at_data>.R")
lint("looking_at_data.R")
lint
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
# Data-analysis
library(rpart)
library(rpart.plot)
library(dplyr)
library(ggplot2)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
install.packages(styler)
library(styler)
library(styler)
install.packages("styler")
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
library(lintr)
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
getwd()
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
input <- readLines("looking_at_data.R")
input <- readLines("looking_at_data.R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
# Data-analysis
library(rpart)
library(rpart.plot)
library(dplyr)
library(ggplot2)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
install.packages("...")
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
input <- readLines("looking_at_data.R")
writeLines(style_text(input), con = "looking_at_data.R")
# Linting
lint("looking_at_data.R")
# Install from CRAN
install.packages("tidyverse")
library(tidyverse)
1 + 1
#| echo: false
2 * 2
1 + 1
1 + 1
1 + 1
#| echo: false
2 * 2
#| echo: true
2 * 2
#| echo: true
2 * 2
#| echo: true
2 * 2
#| echo: true
2 * 2
# Data-analysis
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
library(tidyverse)
#install.packages("...")
39-2
# Create a complex tree
complex_tree <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.0025, minsplit = 5))
# Find optimal CP value
opt_cp <- complex_tree$cptable[which.min(complex_tree$cptable[, "xerror"]), "CP"]
print(opt_cp)
# Calculate the MSEs
MSE_complex <- function() {
train_pred_complex <- predict(complex_tree, train_data)
test_pred_complex <- predict(complex_tree, test_data)
train_mse_complex <- calculate_mse(train_data$G3, train_pred_complex)
test_mse_complex <- calculate_mse(test_data$G3, test_pred_complex)
print(paste("Complex Tree - Training MSE:", train_mse_complex))
print(paste("Complex Tree -     Test MSE:", test_mse_complex))
}
MSE_pruned <- function() {
train_pred_pruned <- predict(pruned_tree, train_data)
test_pred_pruned <- predict(pruned_tree, test_data)
train_mse_pruned <- calculate_mse(train_data$G3, train_pred_pruned)
test_mse_pruned <- calculate_mse(test_data$G3, test_pred_pruned)
print(paste("Pruned Tree - Training MSE:", train_mse_pruned))
print(paste("Pruned Tree - Test MSE:", test_mse_pruned))
}
MSE_complex()
# For tree
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# For regr
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
88*87
88*87
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
library(tidyverse)
#install.packages("...")
library(styler)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.R")
lint("looking_at_data.qmd")
input <- readLines("looking_at_data.qmd")
writeLines(style_text(input), con = "looking_at_data.qmd")
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.qmd")
# not sure why not working anymore but makes sense
# input <- readLines("looking_at_data.qmd")
# writeLines(style_text(input), con = "looking_at_data.qmd")
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.qmd")
# not sure why not working anymore but makes sense
# input <- readLines("looking_at_data.qmd")
# writeLines(style_text(input), con = "looking_at_data.qmd")
load("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R/student_por.RData")
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
# also do basic test if data is working
plot(sd$studytime, sd$G3, col = "blue", pch = 19)
grid()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
View(split_index)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
load("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R/student_por.RData")
library(networkD3)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
# also do basic test if data is working
plot(sd$studytime, sd$G3, col = "blue", pch = 19)
grid()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# Create TREE
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
# Create TREE
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
print(train_mse_tree)
print(valid_mse_tree)
# Create TREE
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
print(train_mse_tree)
print(valid_mse_tree)
# Create REGR
lm_model <- lm(G3 ~ ., data = train_data)
summary(lm_model)
# Calculate MSE for training set
train_pred_regr <- predict(lm_model, train_data)
train_mse_regr <- mean((train_data$G3 - train_pred_regr)^2)
# Calculate MSE for validation set
valid_pred_regr <- predict(lm_model, valid_data)
valid_mse_regr <- mean((valid_data$G3 - valid_pred_regr)^2)
print(train_mse_regr)
print(valid_mse_regr)
p <- ncol(x)
# BART model
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# BART model
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# Fit BART model
bf <- wbart(x, y, nskip = burn, ndpost = nd, printevery = 500)
bart_model <- wbart(x.train = x_train, y.train = y_train, x.test = x_valid, nskip = 1000, ndpost = 1000, printevery = 500)
# BART model
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# Fit BART model
bf <- wbart(x, y, nskip = burn, ndpost = nd, printevery = 500)
# Fit BART model
bf <- wbart(x_train, y_train, nskip = burn, ndpost = nd, printevery = 500)
# Fit BART model
bf <- wbart(x_train, y_train, nskip = 1000, ndpost = 1000, printevery = 500)
bart_model <- wbart(x.train = x_train, y.train = y_train, x.test = x_valid, nskip = 1000, ndpost = 1000, printevery = 500)
# Calculate MSE for BART
train_pred_bart <- bart_model$yhat.train.mean
train_mse_bart <- mean((y_train - train_pred_bart)^2)
valid_pred_bart <- bart_model$yhat.test.mean
valid_mse_bart <- mean((y_valid - valid_pred_bart)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
valid_mse_bart
valid_mse_bart
train_mse_bart
valid_mse_bart
train_mse_bart
valid_mse_bart
valid_mse_bart
train_mse_bart
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.qmd")
# not sure why not working anymore but makes sense
# input <- readLines("looking_at_data.qmd")
# writeLines(style_text(input), con = "looking_at_data.qmd")
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
# also do basic test if data is working
plot(sd$studytime, sd$G3, col = "blue", pch = 19)
grid()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.025, minsplit = 5))
rpart.plot(tree_model, fallen.leaves = TRUE)
tree_model <- rpart(G3 ~ ., data = sd)
rpart.plot(tree_model, shadow.col = "gray")
rpart.plot(tree_model, extra = 101, fallen.leaves = TRUE, type = 4, main = "Regression Tree")
# Get variable importance
var_importance <- tree_model$variable.importance
print(var_importance)
# Variable Importance Plot
var_importance <- data.frame(
variable = names(tree_model$variable.importance),
importance = tree_model$variable.importance
)
ggplot(var_importance, aes(x = reorder(variable, importance), y = importance)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
theme_minimal() +
labs(title = "Variable Importance", x = "Variables", y = "Importance")
lm_model <- lm(G3 ~ ., data = sd)
# Summary
summary_lm <- summary(lm_model)
print(summary_lm)
sd$lm_pred <- predict(lm_model)
sd$tree_pred <- predict(tree_model)
mse_lm <- mean((sd$G3 - sd$lm_pred)^2)
mse_tree <- mean((sd$G3 - sd$tree_pred)^2)
print(mse_lm)
print(mse_tree)
ggplot(sd, aes(x = G3)) +
geom_point(aes(y = lm_pred, color = "Linear Regression"), alpha = 0.5) +
geom_point(aes(y = tree_pred, color = "Regression Tree"), alpha = 0.5) +
geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
theme_minimal() +
labs(
title = "Predicted vs Actual G3 Scores",
x = "Actual G3", y = "Predicted G3",
color = "Model"
) +
scale_color_manual(values = c("Linear Regression" = "blue", "Regression Tree" = "red"))
sd_mini <- sd[, c("Walc", "Dalc", "absences", "G3")]
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
getwd()
setwd("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R")
lint("looking_at_data.qmd")
# not sure why not working anymore but makes sense
# input <- readLines("looking_at_data.qmd")
# writeLines(style_text(input), con = "looking_at_data.qmd")
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
# also do basic test if data is working
plot(sd$studytime, sd$G3, col = "blue", pch = 19)
grid()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.025, minsplit = 5))
rpart.plot(tree_model, fallen.leaves = TRUE)
