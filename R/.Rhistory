marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
p
# Display the plot
p
p <- add_plane(p, split_vars[1], split_points[1], color = "red")
p
p <- add_plane(p, split_vars[2], split_points[2], color = "green")
p
p <- add_plane(p, split_vars[3], split_points[3], color = "blue")
split_vars
split_points
split_vars
p
split_points
sumalc = sd$sumalc
failures = sd$failures
G3 = sd$G3
sd = data.frame(sumalc, failures, G3)
pruned_tree <- rpart(G3 ~ ., data = sd, control = rpart.control(cp = 0.03, minsplit = 5))
rpart.plot(pruned_tree)
# Get the variables used for splitting
split_vars <- pruned_tree$frame$var[pruned_tree$frame$var != "<leaf>"]
split_vars <- unique(as.character(split_vars))
plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
add_markers() %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
####
# Function to add a plane to the plot
add_plane <- function(p, split_var, split_value, color) {
var_range <- range(sd[[split_var]])
other_var <- setdiff(split_vars, split_var)[1]
other_range <- range(sd[[other_var]])
if (split_var == split_vars[1]) {
x <- rep(split_value, 2)
y <- other_range
} else {
x <- var_range
y <- rep(split_value, 2)
}
z <- matrix(rep(range(sd$G3), each = 2), nrow = 2)
add_surface(p, x = x, y = y, z = z, opacity = 0.3, colorscale = list(c(0, 1), c(color, color)))
}
# Get split points
splits <- pruned_tree$splits
split_points <- splits[splits[, "count"] > 0, "index"]
# Create the plot with decision boundaries
p <- plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
p
split_vars
split_points
# Add planes for each split
for (i in 1:2) {
p <- add_plane(p, split_vars[i], split_points[i], color = c("red", "blue")[i])
}
# Display the plot
p <- add_plane(p, split_vars[1], split_points[1], color = "red")
p <- add_plane(p, split_vars[2], split_points[2], color = "green")
p <- add_plane(p, split_vars[3], split_points[3], color = "blue")
plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
add_markers() %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
# Function to add a plane to the plot
add_plane <- function(p, split_var, split_value, color) {
var_range <- range(sd[[split_var]])
other_var <- setdiff(split_vars, split_var)[1]
other_range <- range(sd[[other_var]])
if (split_var == split_vars[1]) {
x <- rep(split_value, 2)
y <- other_range
} else {
x <- var_range
y <- rep(split_value, 2)
}
z <- matrix(rep(range(sd$G3), each = 2), nrow = 2)
add_surface(p, x = x, y = y, z = z, opacity = 0.3, colorscale = list(c(0, 1), c(color, color)))
}
# Get split points
splits <- pruned_tree$splits
split_points <- splits[splits[, "count"] > 0, "index"]
# Create the plot with decision boundaries
p <- plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
p
split_vars
split_points
split_vars
split_vars[3] = "sumalc"
split_vars
split_points
plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
add_markers() %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
# Function to add a plane to the plot
add_plane <- function(p, split_var, split_value, color) {
var_range <- range(sd[[split_var]])
other_var <- setdiff(split_vars, split_var)[1]
other_range <- range(sd[[other_var]])
if (split_var == split_vars[1]) {
x <- rep(split_value, 2)
y <- other_range
} else {
x <- var_range
y <- rep(split_value, 2)
}
z <- matrix(rep(range(sd$G3), each = 2), nrow = 2)
add_surface(p, x = x, y = y, z = z, opacity = 0.3, colorscale = list(c(0, 1), c(color, color)))
}
# Get split points
splits <- pruned_tree$splits
split_points <- splits[splits[, "count"] > 0, "index"]
# Create the plot with decision boundaries
p <- plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
p
split_vars[3] = "sumalc"
split_vars
split_vars[3] = "sumalc"
split_vars
split_points
# Add planes for each split
for (i in 1:2) {
p <- add_plane(p, split_vars[i], split_points[i], color = c("red", "blue")[i])
}
p <- add_plane(p, split_vars[1], split_points[1], color = "red")
p
# Function to add a plane to the plot
add_plane <- function(p, split_var, split_value, color) {
var_range <- range(sd[[split_var]])
other_var <- setdiff(split_vars, split_var)[1]
other_range <- range(sd[[other_var]])
if (split_var == split_vars[1]) {
x <- rep(split_value, 2)
y <- other_range
} else {
x <- var_range
y <- rep(split_value, 2)
}
z <- matrix(rep(range(sd$G3), each = 2), nrow = 2)
add_surface(p, x = x, y = y, z = z, opacity = 0.3, colorscale = list(c(0, 1), c(color, color)))
}
# Function to add a plane to the plot
add_plane <- function(p, split_var, split_value, color) {
var_range <- range(sd[[split_var]])
other_var <- setdiff(split_vars, split_var)[1]
other_range <- range(sd[[other_var]])
if (split_var == split_vars[1]) {
x <- rep(split_value, 2)
y <- other_range
} else {
x <- var_range
y <- rep(split_value, 2)
}
z <- matrix(rep(range(sd$G3), each = 2), nrow = 2)
add_surface(p, x = x, y = y, z = z, opacity = 0.3, colorscale = list(c(0, 1), color))
}
# Get split points
splits <- pruned_tree$splits
split_points <- splits[splits[, "count"] > 0, "index"]
# Create the plot with decision boundaries
p <- plot_ly(sd,
x = ~ get(split_vars[1]), y = ~ get(split_vars[2]), z = ~G3,
type = "scatter3d", mode = "markers",
marker = list(size = 3, color = ~G3, colorscale = "Viridis", opacity = 0.8)
) %>%
layout(scene = list(
xaxis = list(title = split_vars[1]),
yaxis = list(title = split_vars[2]),
zaxis = list(title = "G3")
))
p
split_vars[3] = "sumalc"
split_vars
split_points
p <- add_plane(p, split_vars[1], split_points[1], color = "red")
p
p <- add_plane(p, split_vars[2], split_points[2], color = "green")
p
p <- add_plane(p, split_vars[3], split_points[3], color = "blue")
p
tree_model_2splits <- rpart(G3 ~ ., data = sd, control = rpart.control(maxdepth = 2))
# Plot the tree
rpart.plot(tree_model_2splits, extra = 101, fallen.leaves = TRUE, type = 2, main = "Decision Tree with Two Splits")
sd$tree_pred_2splits <- predict(tree_model_2splits)
mse_tree <- mean((sd$G3 - sd$tree_pred_2splits)^2)
print(mse_tree)
# Split the data based on failures
failures_yes <- subset(sd, failures >= 1)
failures_no <- subset(sd, failures == 0)
# Further split the data
failures_yes_absences_yes <- subset(failures_yes, absences < 1)
lmf <- lm(G3 ~ ., train_data)
plot(bf$sigma, ylim = c(1.5, 5), xlab = "MCMC iteration", ylab = "sigma draw", cex = .5)
plot(bart_model$sigma, ylim = c(1.5, 5), xlab = "MCMC iteration", ylab = "sigma draw", cex = .5)
abline(h = summary(lmf)$sigma, col = "red", lty = 2) # least squares estimates
abline(v = burn, col = "green")
title(main = "sigma draws, green line at burn in, red line at least squares estimate", cex.main = .8)
thin <- 20
ii <- burn + thin * (1:(nd / thin))
acf(bf$sigma[ii], main = "ACF of thinned post burn-in sigma draws")
acf(bart_model$sigma[ii], main = "ACF of thinned post burn-in sigma draws")
fitmat <- cbind(y, bf$yhat.train.mean, bf20$yhat.train.mean)
# Assuming qm is a matrix or data frame
p <- ncol(qm)
rgy <- range(qm, na.rm = TRUE)
# Create the plot
plot(c(1, p), rgy,
type = "n", xlab = "variable",
ylab = "post mean, percent var use", axes = FALSE
)
# Add x-axis
axis(1, at = 1:p, labels = colnames(qm), cex.lab = 0.7, cex.axis = 0.7)
# Create the plot
plot(c(1, p), rgy,
type = "n", xlab = "variable",
ylab = "post mean, percent var use", axes = FALSE
)
plot(bart_model$sigma)
View(bart_model)
?wbart
plot(bart_model$sigma)
##simulate data (example from Friedman MARS paper)
f = function(x){
10*sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2+10*x[,4]+5*x[,5]
}
sigma = 1.0  #y = f(x) + sigma*z , z~N(0,1)
n = 100      #number of observations
set.seed(99)
x = matrix(runif(n*10),n,10) #10 variables, only first 5 matter
Ey = f(x)
y = Ey+sigma*rnorm(n)
lmFit = lm(y~.,data.frame(x,y)) #compare lm fit to BART later
lmFit = lm(y~.,data.frame(x,y)) #compare lm fit to BART later
bartFit = wbart(x,y,nskip=5,ndpost=5)
## Not run:
##run BART
set.seed(99)
bartFit = wbart(x,y)
bartFit = wbart(x,y)
##compare BART fit to linear matter and truth = Ey
fitmat = cbind(y,Ey,lmFit$fitted,bartFit$yhat.train.mean)
##compare BART fit to linear matter and truth = Ey
fitmat = cbind(y,Ey,lmFit$fitted,bartFit$yhat.train.mean)
colnames(fitmat) = c('y','Ey','lm','bart')
print(cor(fitmat))
plot(fitmat)
burn <- 1000
nd <- 1000
y <- sd$G3
bf <- wbart(x, y, nskip = burn, ndpost = nd, printevery = 500)
load("C:/Users/timtj/GitHub/wissenschaftliches-arbeiten/R/student_por.RData")
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
# also do basic test if data is working
plot(sd$studytime, sd$G3, col = "blue", pch = 19)
grid()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# Fit BART model
bart_model <- wbart(
x.train = x_train,
y.train = y_train,
x.test = x_valid,
nskip = 500,
ntree = 100,
ndpost = 500,
printevery = 500)
# tree error
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
# regr error
# Calculate MSE for training set
train_pred_regr <- predict(lm_model, train_data)
train_mse_regr <- mean((train_data$G3 - train_pred_regr)^2)
# Calculate MSE for validation set
valid_pred_regr <- predict(lm_model, valid_data)
valid_mse_regr <- mean((valid_data$G3 - valid_pred_regr)^2)
# BART error
# Calculate MSE for training set
train_pred_bart <- bart_model$yhat.train.mean
train_mse_bart <- mean((y_train - train_pred_bart)^2)
# Calculate MSE for validation set
valid_pred_bart <- bart_model$yhat.test.mean
valid_mse_bart <- mean((y_valid - valid_pred_bart)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse_tree, "\n")
cat("Validation MSE Tree:", valid_mse_tree, "\n\n")
cat("Training MSE   Regr:", train_mse_regr, "\n")
cat("Validation MSE Regr:", valid_mse_regr, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# tree error
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
# regr error
# Calculate MSE for training set
train_pred_regr <- predict(lm_model, train_data)
train_mse_regr <- mean((train_data$G3 - train_pred_regr)^2)
# Calculate MSE for validation set
valid_pred_regr <- predict(lm_model, valid_data)
valid_mse_regr <- mean((valid_data$G3 - valid_pred_regr)^2)
# BART error
# Calculate MSE for training set
train_pred_bart <- bart_model$yhat.train.mean
train_mse_bart <- mean((y_train - train_pred_bart)^2)
# Calculate MSE for validation set
valid_pred_bart <- bart_model$yhat.test.mean
valid_mse_bart <- mean((y_valid - valid_pred_bart)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse_tree, "\n")
cat("Validation MSE Tree:", valid_mse_tree, "\n\n")
cat("Training MSE   Regr:", train_mse_regr, "\n")
cat("Validation MSE Regr:", valid_mse_regr, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = opt_cp-0.0001 , minsplit = 5))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Create REGR
lm_model <- lm(G3 ~ ., data = train_data)
summary(lm_model)
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# Fit BART model
bart_model <- wbart(
x.train = x_train,
y.train = y_train,
x.test = x_valid,
nskip = 500,
ntree = 100,
ndpost = 500,
printevery = 500)
# tree error
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
# regr error
# Calculate MSE for training set
train_pred_regr <- predict(lm_model, train_data)
train_mse_regr <- mean((train_data$G3 - train_pred_regr)^2)
# Calculate MSE for validation set
valid_pred_regr <- predict(lm_model, valid_data)
valid_mse_regr <- mean((valid_data$G3 - valid_pred_regr)^2)
# BART error
# Calculate MSE for training set
train_pred_bart <- bart_model$yhat.train.mean
train_mse_bart <- mean((y_train - train_pred_bart)^2)
# Calculate MSE for validation set
valid_pred_bart <- bart_model$yhat.test.mean
valid_mse_bart <- mean((y_valid - valid_pred_bart)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse_tree, "\n")
cat("Validation MSE Tree:", valid_mse_tree, "\n\n")
cat("Training MSE   Regr:", train_mse_regr, "\n")
cat("Validation MSE Regr:", valid_mse_regr, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
# Prepare data for BART
x_train <- train_data[, !names(train_data) %in% "G3"]
y_train <- train_data$G3
x_valid <- valid_data[, !names(valid_data) %in% "G3"]
y_valid <- valid_data$G3
# Fit BART model
bart_model <- wbart(
x.train = x_train,
y.train = y_train,
x.test = x_valid,
nskip = 1000,
ntree = 200,
ndpost = 1000,
printevery = 500)
# tree error
# Calculate MSE for training set
train_pred_tree <- predict(tree_model, train_data)
train_mse_tree <- mean((train_data$G3 - train_pred_tree)^2)
# Calculate MSE for validation set
valid_pred_tree <- predict(tree_model, valid_data)
valid_mse_tree <- mean((valid_data$G3 - valid_pred_tree)^2)
# regr error
# Calculate MSE for training set
train_pred_regr <- predict(lm_model, train_data)
train_mse_regr <- mean((train_data$G3 - train_pred_regr)^2)
# Calculate MSE for validation set
valid_pred_regr <- predict(lm_model, valid_data)
valid_mse_regr <- mean((valid_data$G3 - valid_pred_regr)^2)
# BART error
# Calculate MSE for training set
train_pred_bart <- bart_model$yhat.train.mean
train_mse_bart <- mean((y_train - train_pred_bart)^2)
# Calculate MSE for validation set
valid_pred_bart <- bart_model$yhat.test.mean
valid_mse_bart <- mean((y_valid - valid_pred_bart)^2)
# Print results
comp <- function() {
cat("Training MSE   Tree:", train_mse_tree, "\n")
cat("Validation MSE Tree:", valid_mse_tree, "\n\n")
cat("Training MSE   Regr:", train_mse_regr, "\n")
cat("Validation MSE Regr:", valid_mse_regr, "\n\n")
cat("Training MSE   BART:", train_mse_bart, "\n")
cat("Validation MSE BART:", valid_mse_bart, "\n")
}
comp()
bart_model
plot(bart_model$sigma)
?wbart
plot(bart_model$sigma)
plot(bart_model$sigma, ylim = c(1.5, 5), xlab = "MCMC iteration", ylab = "sigma draw", cex = .5)
thin <- 20
library(tidyverse)
library(rpart)
library(rpart.plot)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
library(lintr)
library(styler)
