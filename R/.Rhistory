valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.038, minsplit = 5))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Comparing Trees and Linear regression ----
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
# execute this for manual testing
tree_model <- rpart(G3 ~ ., data = train_data, control = rpart.control(cp = 0.03, minsplit = 40))
rpart.plot(tree_model, fallen.leaves = TRUE)
# Calculate MSE for training set
train_pred <- predict(tree_model, train_data)
train_mse <- mean((train_data$G3 - train_pred)^2)
# Calculate MSE for validation set
valid_pred <- predict(tree_model, valid_data)
valid_mse <- mean((valid_data$G3 - valid_pred)^2)
# Print results
lm_model <- lm(G3 ~ ., data = train_data)
# Summary
summary_lm <- summary(lm_model)
# Calculate MSE for training set
train_predL <- predict(lm_model, train_data)
train_mseL <- mean((train_data$G3 - train_predL)^2)
# Calculate MSE for validation set
valid_predL <- predict(lm_model, valid_data)
valid_mseL <- mean((valid_data$G3 - valid_predL)^2)
# Print results
comp <- function(){
cat("Training MSE   Tree:", train_mse, "\n")
cat("Validation MSE Tree:", valid_mse, "\n\n")
cat("Training MSE   Regr:", train_mseL, "\n")
cat("Validation MSE Regr:", valid_mseL, "\n\n")
}
comp()
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
burn = 1000; nd = 1000
y = sd$G3
y = train_data$G3
View(train_data)
print([1:10])
print(1:10)
print(1:10,16)
fix = c(1:28)
fix
fix = c(1:28, 30)
fix
burn = 1000; nd = 1000
fix = c(1:28, 30)
y = train_data$G3
x = train_data[,fix]
p = ncol(x)
bf = wbart(x,y,nskip=burn,ndpost=nd,printevery=500)
lmf = lm(G3~., sd)
lmf = lm(G3~., train_data)
plot(bf$sigma,ylim=c(1.5,5),xlab="MCMC iteration",ylab="sigma draw",cex=.5)
abline(h=summary(lmf)$sigma,col="red",lty=2) #least squares estimates
abline(v = burn,col="green")
title(main="sigma draws, green line at burn in, red line at least squares estimate",cex.main=.8)
thin = 20
ii = burn + thin*(1:(nd/thin))
acf(bf$sigma[ii],main="ACF of thinned post burn-in sigma draws")
# making small BART model to compare
bf20 = wbart(x,y,nskip=burn,ndpost=nd, ntree = 20,printevery=500)
fitmat = cbind(y,bf$yhat.train.mean,bf20$yhat.train.mean)
colnames(fitmat) = c("y","yhatBART","yhatBART20")
pairs(fitmat)
print(cor(fitmat))
dim(bf20$varcount)
# Split the data into training (70%) and validation (30%) sets
split_index <- createDataPartition(sd$G3, p = 0.7, list = FALSE)
train_data <- sd[split_index, ]
valid_data <- sd[-split_index, ]
burn = 1000; nd = 1000
fix = c(1:28, 30)
y = train_data$G3
x = train_data[,fix]
p = ncol(x)
bf = wbart(x,y,nskip=burn,ndpost=nd,printevery=500)
# Calculate MSE for training set
train_pred <- predict(bf, train_data)
View(bf)
# Data-analysis
library(rpart)
library(rpart.plot)
library(dplyr)
library(ggplot2)
library(data.tree)
library(networkD3)
library(plotly)
library(caret)
library(BART)
# 1. Setting up data ----
sd <- data.frame(student_por)
sd <- sd %>%
mutate_if(is.character, as.factor)
sd$sumalc <- sd$Walc + sd$Dalc
sd$Dalc <- NULL
sd$Walc <- NULL
# Removing these because that would just be cheating
sd$G2 <- NULL
sd$G1 <- NULL
sd = clean
tree_model <- rpart(G3 ~ ., data = sd)
rpart.plot(tree_model, shadow.col = "gray")
tree_model <- rpart(G3 ~ ., data = sd)
rpart.plot(tree_model, shadow.col = "gray")
rpart.plot(tree_model, extra = 101, fallen.leaves = TRUE, type = 4, main = "Regression Tree")
rpart.plot(tree_model, shadow.col = "gray")
